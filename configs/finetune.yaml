batch_size: 2

#queue_size: 57600
queue_size: 16384
alpha: 0.4

freeze_text: false
freeze_seq: false

# optimizer
weight_decay: 0.05
init_lr: 1e-5
max_epoch: 100


model: 'protbert'
seq_config: 'config_seq.json'

corrupt_strategy: 'none'
match: 'partial_local_align'
ab: 'finetune'

dataset: 'localization_v9'

corrupt_percentage: 0

modified_decoder: false

name: 'ft_localization_v9'

num_of_layer: 1