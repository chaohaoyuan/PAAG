batch_size: 2

#queue_size: 57600
queue_size: 16384
alpha: 0.4

freeze_text: false
freeze_seq: false

# optimizer
weight_decay: 0.05
init_lr: 3e-5
max_epoch: 100


model: 'protbert'
seq_config: 'config_seq.json'

corrupt_strategy: 'none'
match: 'partial_local_align'

dataset: 'uniprot_location'

corrupt_percentage: 0

modified_decoder: false

name: '16384_lower_case_partial_textual_local_16card_ddpbf16_full_3e-5_1_layer_flexible_length_decoder'

num_of_layer: 1